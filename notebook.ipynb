{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5d6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import pywhisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3721b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES=1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RUTA_GRABACIONES= \"./grabaciones\"\n",
    "os.makedirs(RUTA_GRABACIONES, exist_ok=True)\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(\n",
    "                format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=FRAMES\n",
    "                )\n",
    "print(f\"Comienzo de la grabación...\")\n",
    "frames=[]\n",
    "segundos=10\n",
    "for j in range(0,int(RATE/FRAMES*segundos)):\n",
    "    data=stream.read(FRAMES)\n",
    "    frames.append(data)\n",
    "\n",
    "print(f\"Fin de la grabación...\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "filename = os.path.join(RUTA_GRABACIONES, f\"grabacion.wav\")\n",
    "with wave.open(filename, 'wb') as wf:\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(2)  \n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "\n",
    "p.terminate()\n",
    "\n",
    "print(\"Grabacion completadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def transcribir_audio(archivo_audio):\n",
    "    modelo = pywhisper.load_model(\"base\", device=device)  # Puedes ajustar el modelo según tus necesidades\n",
    "    resultado = modelo.transcribe(archivo_audio)\n",
    "    return ' '.join(dic['text'] for dic in resultado['segments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4466223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "def summarize_long_text(text, chunk_size=512):\n",
    "    \"\"\"Summarizes a long text by splitting it into chunks.\"\"\"\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    summary_chunks = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        summary_chunks.append(summarizer(chunk, max_length=130, min_length=30, do_sample=False)[0]['summary_text'])\n",
    "\n",
    "    return \" \".join(summary_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dde1bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:05<00:00, 28.7MiB/s]\n",
      "c:\\Users\\rafae\\Desktop\\AINE_AUDIO_SUMMARIZE\\.venv\\Lib\\site-packages\\pywhisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hola, esto es una prueba, prueba probando, probando, lista de la compra, huevos, leche,  feriales y miel.\n"
     ]
    }
   ],
   "source": [
    "transcripcion = transcribir_audio(\"./grabaciones/grabacion.wav\")\n",
    "print(transcripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 46. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de la compra, huevos, leche,  feriales y miel. Hola, esto es una prueba.\n"
     ]
    }
   ],
   "source": [
    "resumen = summarize_long_text(transcripcion)\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bajaro de los Nacionales volando por arriba de la feria de Sevilla\n",
      "Bajaro de los Nacionales volando por arriba de la feria de Sevilla. Bajaro   volando  por ariba de the feria.\n"
     ]
    }
   ],
   "source": [
    "transcripcion = transcribir_audio(\"./grabaciones/WhatsApp Audio 2025-05-10 at 17.24.20_2448ebda.opus\")\n",
    "print(transcripcion)\n",
    "resumen = summarize_long_text(transcripcion)\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:49<00:00, 16.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER: \n",
      "Describe el video. ASSISTANT: The video shows a group of people dressed in religious attire, including robes and hats, sitting in rows and listening to a speaker who is likely a religious figure, possibly a priest or a bishop, given the context. The setting appears to be a formal religious event, possibly a sermon or a lecture, given the presence of the religious figure and the attire of the attendees. The attendees are focused on the speaker, and the speaker is addressing them\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import LlavaNextVideoProcessor, LlavaNextVideoForConditionalGeneration\n",
    "\n",
    "model_id = \"llava-hf/LLaVA-NeXT-Video-7B-hf\"\n",
    "\n",
    "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(device)\n",
    "\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(model_id)\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "# define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\", \"video\") \n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe el video.\"},\n",
    "            {\"type\": \"video\"},\n",
    "            ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "video_path = \"./grabaciones/videoplayback.mp4\"\n",
    "container = av.open(video_path)\n",
    "\n",
    "# sample uniformly 8 frames from the video, can sample more for longer videos\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
    "clip = read_video_pyav(container, indices)\n",
    "inputs_video = processor(text=prompt, videos=clip, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs_video, max_new_tokens=100, do_sample=False)\n",
    "print(processor.decode(output[0][2:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n"
     ]
    }
   ],
   "source": [
    "resumen = summarize_long_text(processor.decode(output[0][2:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video shows a group of people dressed in religious attire. The setting appears to be a formal religious event. The attendees are focused on the speaker, and the speaker is addressing them.\n"
     ]
    }
   ],
   "source": [
    "print(resumen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
